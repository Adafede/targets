% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tar_knitr.R
\name{tar_knitr}
\alias{tar_knitr}
\title{Include a knitr or R Markdown report in a pipeline.}
\usage{
tar_knitr(path)
}
\arguments{
\item{path}{Character of length 1, path to the \code{knitr} or
R Markdown source file.}
}
\value{
A language object that represents the dependencies and
return value of a \code{knitr} source dynamic file.
}
\description{
Register a knitr or R Markdown report as part of a dynamic
target. Relies on tidy evaluation to insert a special expression into
the target's command when the target is defined.
}
\details{
\code{tar_knitr()} tells \code{targets} to look for dependency targets
in the active code chunks of the report. These dependencies
must be mentioned as literal symbols in explicit calls to
\code{\link[=tar_load]{tar_load()}} and \code{\link[=tar_read]{tar_read()}}. This mechanism not only rerenders
the report automatically when the dependencies change, but also
allows you to run the report by itself (outside the pipeline)
as long as a \verb{_targets/} data store already exists in the current
working directory and contains the data.
}
\section{Working directory}{

The current working directory (i.e. \code{getwd()}) must contain the
\verb{_targets/} data store not only when \code{tar_knitr()} is evaluated,
but also when the actual report is run. The easiest way to
deal with this is just to keep all your R Markdown source files
at the root directory of the project. If you need to keep your report
somewhere else, such as a subdirectory,
consider setting \code{knit_root_dir = getwd()} in \code{rmarkdown::render()} or
\code{knitr::opts_knit$set(root.dir = "your_project_root_directory")}
in an early code chunk of the report itself.
}

\examples{
\dontrun{
tar_dir({
# Here is a path to an example R Markdown report that depends on
# targets data, data2, and analysis.
path <- system.file("example_knitr_report.Rmd", package = "targets")
# `tar_knitr()` defines a piece of code with the dependencies
# of the report as symbols so the code analyzer can detect them.
expr <- tar_knitr(path)
expr
# If you evaluate the expression, you get the path to the report,
# which is exactly what we want for dynamic files (`format = "file"`).
eval(expr, envir = list(analysis = 1, data = 1, data2 = 1))
# In your actual pipeline, write a dynamic file (`format = "file"`) target
# to run the report and return the paths to the source and output.
# (`!!tar_knitr("report.Rmd")` returns `"report.Rmd"`, and it requires
# `tidy_eval` to be `TRUE` in [tar_target()] (default).
file.copy(path, "report.Rmd")
tar_script({
  tar_options()
  tar_pipeline(
    tar_target(data, create_data()), # You define create_data().
    tar_target(analysis, analyze_data(data)), # You define analyze_data().
    tar_target(
      report, {
        rmarkdown::render("report.Rmd")
        c(!!tar_knitr("report.Rmd"), "report.html")
      },
      format = "file"
    )
  )
})
# In the graph below,
# notice how report depends on data and analysis
# because of the calls to tar_load() and tar_read() in the report
# and the use of !!tar_knitr() in the target.
tar_visnetwork()
})
}
}
