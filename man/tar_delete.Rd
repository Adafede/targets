% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tar_delete.R
\name{tar_delete}
\alias{tar_delete}
\title{Delete target output values.}
\usage{
tar_delete(
  names,
  cloud = TRUE,
  batch_size = 1000L,
  verbose = TRUE,
  store = targets::tar_config_get("store")
)
}
\arguments{
\item{names}{Names of the targets to remove from \verb{_targets/objects/}.
You can supply symbols
or \code{tidyselect} helpers like \code{\link[=any_of]{any_of()}} and \code{\link[=starts_with]{starts_with()}}.}

\item{cloud}{Logical of length 1, whether to delete objects
from the cloud if applicable (e.g. AWS, GCP). If \code{FALSE},
files are not deleted from the cloud.}

\item{batch_size}{Positive integer between 1 and 1000,
number of target objects to delete
from the cloud with each HTTP API request.
Currently only supported for AWS.
Cannot be more than 1000.}

\item{verbose}{Logical of length 1, whether to print console messages
to show progress when deleting each batch of targets from each
cloud bucket. Batched deletion with verbosity is currently only supported
for AWS.}

\item{store}{Character of length 1, path to the
\code{targets} data store. Defaults to \code{tar_config_get("store")},
which in turn defaults to \verb{_targets/}.
When you set this argument, the value of \code{tar_config_get("store")}
is temporarily changed for the current function call.
See \code{\link[=tar_config_get]{tar_config_get()}} and \code{\link[=tar_config_set]{tar_config_set()}} for details
about how to set the data store path persistently
for a project.}
}
\description{
Delete the output values of targets in \verb{_targets/objects/}
(or the cloud if applicable)
but keep the records in the metadata.
}
\details{
If you have a small number of data-heavy targets you
need to discard to conserve storage, this function can help.
Local external files files (i.e. \code{format = "file"}
and \code{repository = "local"}) are not deleted.
For targets with \code{repository} not equal \code{"local"}, \code{tar_delete()} attempts
to delete the file and errors out if the deletion is unsuccessful.
If deletion fails, either log into the cloud platform
and manually delete the file (e.g. the AWS web console
in the case of \code{repository = "aws"}) or call
\code{\link[=tar_invalidate]{tar_invalidate()}} on that target so that \code{targets}
does not try to delete the object.
For patterns recorded in the metadata, all the branches
will be deleted. For patterns no longer in the metadata,
branches are left alone.
}
\section{Storage access}{

Several functions like \code{tar_make()}, \code{tar_read()}, \code{tar_load()},
\code{tar_meta()}, and \code{tar_progress()} read or modify
the local data store of the pipeline.
The local data store is in flux while a pipeline is running,
and depending on how distributed computing or cloud computing is set up,
not all targets can even reach it. So please do not call these
functions from inside a target as part of a running
pipeline. The only exception is literate programming
target factories in the \code{tarchetypes} package such as \code{tar_render()}
and \code{tar_quarto()}.


Several functions like \code{tar_make()}, \code{tar_read()}, \code{tar_load()},
\code{tar_meta()}, and \code{tar_progress()} read or modify
the local data store of the pipeline.
The local data store is in flux while a pipeline is running,
and depending on how distributed computing or cloud computing is set up,
not all targets can even reach it. So please do not call these
functions from inside a target as part of a running
pipeline. The only exception is literate programming
target factories in the \code{tarchetypes} package such as \code{tar_render()}
and \code{tar_quarto()}.
}

\section{Cloud target data versioning}{

Some buckets in Amazon S3 or Google Cloud Storage are "versioned",
which means they track historical versions of each data object.
If you use \code{targets} with cloud storage
(\url{https://books.ropensci.org/targets/cloud-storage.html})
and versioning is turned on, then \code{targets} will record each
version of each target in its metadata.

However, by default,
\code{targets} \emph{uses} only the latest version in the bucket.
You may instead want to
use the specific version of the target recorded in the local metadata
(for example, if you previously committed the metadata file
\verb{_targets/meta/meta} to version control, and now you want to roll
back the code and data together to an earlier point in time).
To do this, you will
need to modify the \code{resources} argument of \code{\link[=tar_target]{tar_target()}} and/or
\code{\link[=tar_option_set]{tar_option_set()}} via \code{\link[=tar_resources]{tar_resources()}}. In \code{\link[=tar_resources_aws]{tar_resources_aws()}}
or \code{\link[=tar_resources_gcp]{tar_resources_gcp()}}, set the \code{version} argument to \code{"meta"}.
Modifying your code this way in \verb{_targets.R} will control functions that
read \verb{_targets.R} when they run, such as \code{\link[=tar_make]{tar_make()}}, \code{\link[=tar_outdated]{tar_outdated()}},
and \code{\link[=tar_visnetwork]{tar_visnetwork()}}. To apply \code{version = "meta"} to functions that
do not read \verb{_targets.R}, such as \code{\link[=tar_read]{tar_read()}} and \code{\link[=tar_load]{tar_load()}},
set \code{resources} in \code{\link[=tar_option_set]{tar_option_set()}} in your local R session.
You can do this manually, or if you coded those options in \verb{_targets.R},
you can manually run \verb{_targets.R} using \code{\link[=tar_load_globals]{tar_load_globals()}}.
}

\examples{
if (identical(Sys.getenv("TAR_EXAMPLES"), "true")) { # for CRAN
tar_dir({ # tar_dir() runs code from a temp dir for CRAN.
tar_script({
  list(
    tar_target(y1, 1 + 1),
    tar_target(y2, 1 + 1),
    tar_target(z, y1 + y2)
  )
}, ask = FALSE)
tar_make()
tar_delete(starts_with("y")) # Only deletes y1 and y2.
tar_make() # y1 and y2 rebuild but return same values, so z is up to date.
})
}
}
\seealso{
Other clean: 
\code{\link{tar_destroy}()},
\code{\link{tar_invalidate}()},
\code{\link{tar_prune_list}()},
\code{\link{tar_prune}()}
}
\concept{clean}
