% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tar_repository_cas_local.R
\name{tar_repository_cas_local}
\alias{tar_repository_cas_local}
\title{Local content-addressable storage (CAS) repository
(an experimental feature).}
\usage{
tar_repository_cas_local(path = NULL, consistent = FALSE)
}
\arguments{
\item{path}{Character string, file path to the CAS repository
where all the data object files will be stored. \code{NULL} to default to
\code{file.path(tar_config_get("store"), "cas")} (usually \code{"_targets/cas/"}).}

\item{consistent}{Logical. Set to \code{TRUE} if the storage platform is
strongly read-after-write consistent. Set to \code{FALSE} if the platform
is not necessarily strongly read-after-write consistent.

A data storage system is said to have strong read-after-write consistency
if a new object is fully available for reading as soon as the write
operation finishes. Many modern cloud services like Amazon S3 and
Google Cloud Storage have strong read-after-write consistency,
meaning that if you upload an object with a PUT request, then a
GET request immediately afterwards will retrieve the precise
version of the object you just uploaded.

Some storage systems do not have strong read-after-write consistency.
One example is network file systems (NFS). On a computing cluster,
if one node creates a file on an NFS, then there is a delay before
other nodes can access the new file. \code{targets} handles this situation
by waiting for the new file to appear with the correct hash
before attempting to use it in downstream computations.
\code{consistent = FALSE} imposes a waiting period in which \code{targets}
repeatedly calls the \code{exists} method until the file becomes available
(at time intervals configurable with \code{\link[=tar_resources_network]{tar_resources_network()}}).
These extra calls to \code{exists} may come with a
little extra latency / computational burden,
but on systems which are not strongly read-after-write consistent,
it is the only way \code{targets} can safely use the current results
for downstream computations.}
}
\value{
A character string from \code{\link[=tar_repository_cas]{tar_repository_cas()}} which may be
passed to the \code{repository} argument of \code{\link[=tar_target]{tar_target()}} or
\code{\link[=tar_option_set]{tar_option_set()}} to use a local CAS system.
}
\description{
Local content-addressable storage (CAS) repository.
}
\details{
Pass to the \code{repository} argument of \code{\link[=tar_target]{tar_target()}} or
\code{\link[=tar_option_set]{tar_option_set()}} to use a local CAS system.
}
\section{Content-addressable storage}{

Without content-addressable storage (CAS),
the output data of a pipeline is organized based
on the names of the targets. For example,
if your pipeline has a target \code{x},
then by default \code{\link[=tar_make]{tar_make()}} will store the data in a file
at \verb{_targets/objects/x}.
Here, the storage location of \code{x} depends on its target name.

Content-addressable storage (CAS) is different:
output files are organized based on their contents, not target names.
In a CAS system, the name of each output object is its hash, and the
metadata in
\code{tar_meta(fields = any_of(c("name", "data")), targets_only = TRUE)}
maps target names to object names.

CAS is ideal for data versioning and collaboration
because it accrues an ever-growing collection of historical objects
that the metadata can reassign to different target names as needed.
For example, if your code and metadata (\verb{_targets/meta/meta})
are in the same version-controlled source code repository and you
revert to a previous commit, then you can revisit a historical
version of your pipeline with your targets still up to date.
And in collaborative settings, you can fork your colleague's
code and metadata and leverage their up-to-date targets.

The weakness of CAS is the heavy buildup of data objects over time.
Whereas non-CAS storage maintains only the current version of target
\code{x} at any given time, a CAS system maintains each version of \code{x}
in its own file. Over time, this adds up to a lot of data and
a lot of files. Most pipelines using CAS
should have a garbage collection system to remove objects no longer
needed. This could involve removing files with sufficiently old
access dates, or if historical versioning is not desired,
removing files no longer in \code{tar_meta()$data}.

See the \code{\link[=tar_repository_cas_local]{tar_repository_cas_local()}} function for an example
CAS system based on a local folder on disk.
It uses \code{\link[=tar_cas_u]{tar_cas_u()}} for uploads,
\code{\link[=tar_cas_d]{tar_cas_d()}} for downloads, and
\code{\link[=tar_cas_e]{tar_cas_e()}} for existence.
See the "Repository functions" section for specific advice on how
to write your own methods.
}

\examples{
if (identical(Sys.getenv("TAR_EXAMPLES"), "true")) { # for CRAN
tar_dir({ # tar_dir() runs code from a temp dir for CRAN.
tar_script({
  repository <- tar_repository_cas_local("cas")
  write_file <- function(object) {
    writeLines(as.character(object), "file.txt")
    "file.txt"
  }
  list(
    tar_target(x, c(2L, 4L), repository = repository),
    tar_target(
      y,
      x,
      pattern = map(x),
      format = "qs",
      repository = repository
    ),
    tar_target(z, write_file(y), format = "file", repository = repository)
  )
})
tar_make()
tar_read(y)
tar_read(z)
list.files("cas")
tar_meta(any_of(c("x", "z")), fields = any_of("data"))
})
}
}
\seealso{
Other content-addressable storage: 
\code{\link{tar_repository_cas}()},
\code{\link{tar_repository_cas_local_gc}()}
}
\concept{content-addressable storage}
